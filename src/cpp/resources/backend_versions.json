{
  "comment": "This configuration file controls which llama.cpp, whisper.cpp, and FLM versions are downloaded for each backend. You can modify these values to pin specific versions without rebuilding the application.",
  "llamacpp": {
    "vulkan": "b7426",
    "rocm": "b1136",
    "metal": "b7426",
    "cpu": "b7426"
  },
  "whispercpp": "v1.8.2",
  "flm": {
    "version": "v0.9.25",
    "min_npu_driver": "32.0.203.304"
  }
}

